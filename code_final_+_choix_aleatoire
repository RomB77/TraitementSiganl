import librosa
import numpy as np
import matplotlib.pyplot as plt
from midiutil import MIDIFile             #http://midiutil.readthedocs.io/en/1.2.1/
from collections import Counter
#from mido import Message, MidiFile, MidiTrack




##### Récupération du fichier

import pandas as pd
import os
import random
from pydub import AudioSegment
from pydub.playback import play
import tempfile
import librosa
import librosa.display 
# Redéfinir le répertoire temporaire
temp_dir = r'C:\Users\CYTech Student\Documents\temp_files'
if not os.path.exists(temp_dir):
    os.makedirs(temp_dir)
tempfile.tempdir = temp_dir

# Configurer le chemin vers ffmpeg
AudioSegment.converter = r'C:\Users\CYTech Student\AppData\Local\Programs\Python\Python312\ffmpeg-2024-11-21-git-f298507323-full_build\bin\ffmpeg.exe'

# Étape 1 : Charger le fichier Excel
fichier_excel = './Base_de_donnees.xlsx'  # Chemin du fichier Excel
dossier_audio = './base_de_donnees_finale/'  # Chemin où les fichiers audio .wav sont stockés

# Charger le fichier Excel
data = pd.read_excel(fichier_excel)

# Étape 2 : Filtrer les lignes où num_instru == 1
filtered_data = data[data['num_instru'] == 1]

#Etape 3 : Définir le dictionnaira d'instruments:
dict_instrum={
    "cel": "Cello",
    "cla" : "Clarinet",
    "flu" : "flute",
    "gac": "Acoustic Guitar",
    "gel": "Electric Guitar",
    "org": "Organ",
    "pia": "Piano",
    "sax": "Saxophone",
    "tru": "Trumpet",
    "vio": "Violin",
    "voi" : "Voix humaine",
    }

if filtered_data.empty:
    print("Aucune ligne avec num_instru == 1 n'a été trouvée.")
else:
    # Étape 3 : Sélectionner une ligne aléatoire qui ne contient pas la voix humaine
    ligne_aleatoire = filtered_data.sample(n=1)
    instrum_fichier = ligne_aleatoire['Content'].values[0]
    while "voi" in instrum_fichier:
        ligne_aleatoire = filtered_data.sample(n=1)
        instrum_fichier = ligne_aleatoire['Content'].values[0]
    nom_fichier = ligne_aleatoire['File Name'].values[0]
    while '\t' in instrum_fichier or '\n' in instrum_fichier: 
        instrum_fichier =instrum_fichier[:-2]
    instrument =dict_instrum[instrum_fichier]
    # Étape 4 : Construire le chemin du fichier audio
    chemin_fichier_audio = os.path.join(dossier_audio, nom_fichier)

    if not os.path.exists(chemin_fichier_audio):
        print(f"Le fichier audio {chemin_fichier_audio} est introuvable.")
    else:
        # Charger le fichier audio
        print(f"Fichier audio sélectionné : {nom_fichier}")
        print(f"Instrument utilisé : {instrument}")

        # Demander à l'utilisateur s'il veut jouer le fichier audio
        choix = input("Voulez-vous jouer ce fichier audio ? (oui/non) : ").strip().lower()

        if choix == 'oui':
            # Lire le fichier audio avec pygame
            import pygame
            pygame.mixer.init()

            # Exporter temporairement
            audio = AudioSegment.from_file(chemin_fichier_audio, format="wav")
            temp_audio_path = os.path.join(temp_dir, 'temp_audio.wav')
            audio.export(temp_audio_path, format="wav")

            # Jouer l'audio
            pygame.mixer.music.load(temp_audio_path)
            pygame.mixer.music.play()

            print("Lecture en cours...")

            # Attendre que l'audio termine
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)

            print("Lecture terminée.")
        else:
            print("Lecture annulée.")

# Charger un fichier audio
y, sr = librosa.load(chemin_fichier_audio, sr=16000)

instruments = {
    0: 'Acoustic Grand Piano',
    1: 'Bright Acoustic Piano',
    2: 'Electric Grand Piano',
    3: 'Honky-tonk Piano',
    4: 'Electric Piano 1',
    5: 'Electric Piano 2',
    6: 'Harpsichord',
    7: 'Clavinet',
    8: 'Celesta',
    9: 'Glockenspiel',
    10: 'Music Box',
    11: 'Vibraphone',
    12: 'Marimba',
    13: 'Xylophone',
    14: 'Tubular Bells',
    15: 'Dulcimer',
    16: 'Drawbar Organ',
    17: 'Percussive Organ',
    18: 'Rock Organ',
    19: 'Church Organ',
    20: 'Reed Organ',
    21: 'Accordion',
    22: 'Harmonica',
    23: 'Tango Accordion',
    24: 'Acoustic Guitar (nylon)',
    25: 'Acoustic Guitar (steel)',
    26: 'Electric Guitar (jazz)',
    27: 'Electric Guitar (clean)',
    28: 'Electric Guitar (muted)',
    29: 'Overdriven Guitar',
    30: 'Distortion Guitar',
    31: 'Guitar Harmonics',
    32: 'Acoustic Bass',
    33: 'Electric Bass (finger)',
    34: 'Electric Bass (pick)',
    35: 'Fretless Bass',
    36: 'Slap Bass 1',
    37: 'Slap Bass 2',
    38: 'Synth Bass 1',
    39: 'Synth Bass 2',
    40: 'Violin',
    41: 'Viola',
    42: 'Cello',
    43: 'Contrabass',
    44: 'Tremolo Strings',
    45: 'Pizzicato Strings',
    46: 'Orchestral Harp',
    47: 'Timpani',
    48: 'String Ensemble 1',
    49: 'String Ensemble 2',
    50: 'Synth Strings 1',
    51: 'Synth Strings 2',
    52: 'Choir Aahs',
    53: 'Voice Oohs',
    54: 'Synth Choir',
    55: 'Orchestra Hit',
    56: 'Trumpet',
    57: 'Trombone',
    58: 'Tuba',
    59: 'Muted Trumpet',
    60: 'French Horn',
    61: 'Brass Section',
    62: 'Synth Brass 1',
    63: 'Synth Brass 2',
    64: 'Soprano Sax',
    65: 'Alto Sax',
    66: 'Tenor Sax',
    67: 'Baritone Sax',
    68: 'Oboe',
    69: 'English Horn',
    70: 'Bassoon',
    71: 'Clarinet',
    72: 'Piccolo',
    73: 'Flute',
    74: 'Recorder',
    75: 'Pan Flute',
    76: 'Blown Bottle',
    77: 'Shakuhachi',
    78: 'Whistle',
    79: 'Ocarina',
    80: 'Lead 1 (square)',
    81: 'Lead 2 (sawtooth)',
    82: 'Lead 3 (calliope)',
    83: 'Lead 4 (chiff)',
    84: 'Lead 5 (charang)',
    85: 'Lead 6 (voice)',
    86: 'Lead 7 (fifths)',
    87: 'Lead 8 (bass + lead)',
    88: 'Pad 1 (new age)',
    89: 'Pad 2 (warm)',
    90: 'Pad 3 (polysynth)',
    91: 'Pad 4 (choir)',
    92: 'Pad 5 (bowed)',
    93: 'Pad 6 (metallic)',
    94: 'Pad 7 (halo)',
    95: 'Pad 8 (sweep)',
    96: 'FX 1 (rain)',
    97: 'FX 2 (soundtrack)',
    98: 'FX 3 (crystal)',
    99: 'FX 4 (atmosphere)',
    100: 'FX 5 (brightness)',
    101: 'FX 6 (goblins)',
    102: 'FX 7 (echoes)',
    103: 'FX 8 (sci-fi)',
    104: 'Sitar',
    105: 'Banjo',
    106: 'Shamisen',
    107: 'Koto',
    108: 'Kalimba',
    109: 'Bagpipe',
    110: 'Fiddle',
    111: 'Shanai',
    112: 'Tinkle Bell',
    113: 'Agogo',
    114: 'Steel Drums',
    115: 'Woodblock',
    116: 'Taiko Drum',
    117: 'Melodic Tom',
    118: 'Synth Drum',
    119: 'Reverse Cymbal',
    120: 'Guitar Fret Noise',
    121: 'Breath Noise',
    122: 'Seashore',
    123: 'Bird Tweet',
    124: 'Telephone Ring',
    125: 'Helicopter',
    126: 'Applause',
    127: 'Gunshot',
    128: 'Piano',
}

# Adapter les paramètres en fonction du tempo
#nfft = 2048 # Si le tempo est rapide (arbitrairement au-dessus de 120 BPM) on réduire la taille de la fenêtre pour une meilleure résolution temporelle
nfft = min(1024, len(y))
hop_length = nfft //4 #décalage de 25% de la fenêtre

# Calcul du spectrogramme
D = librosa.stft(y, n_fft=nfft, hop_length=hop_length)
S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

# Affichage du spectrogramme
plt.figure(figsize=(10, 6))
librosa.display.specshow(S_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='hz')
plt.colorbar(format='%+2.0f dB')
plt.title('Spectrogramme')
plt.savefig("spectogramme.png")
plt.close()
#plt.show()

# Détection des débuts (onsets) en temps
onset_frames = librosa.onset.onset_detect(y=y, sr=sr, hop_length=512, units='frames')
onset_times = librosa.frames_to_time(onset_frames, sr=sr)

# Ajouter un point final pour couvrir le dernier segment
onset_times = np.append(onset_times, librosa.get_duration(y=y, sr=sr))

# Liste pour stocker les notes détectées
detected_notes = []

def note_to_midi(note_name):
    # Liste des noms des notes
    note_base = {'C': 0, 'C♯': 1, 'D': 2, 'D♯': 3, 'E': 4, 'F': 5, 'F♯': 6, 
                 'G': 7, 'G♯': 8, 'A': 9, 'A♯': 10, 'B': 11}
    
    # Extraction de la note et de l'octave
    note = note_name[:-1]  # Partie lettre (e.g., 'C', 'D#')
    octave = int(note_name[-1])  # Partie chiffre (e.g., 4)
    
    # Calcul du numéro MIDI
    midi_number = 12 * (octave + 1) + note_base[note]
    return midi_number

def octave(note_prec, note_suiv) :
    if len(note_prec) == 2 and len(note_suiv) == 2 :
        if note_prec[0] == note_suiv[0] :
            return False
    if len(note_prec) == 3 and len(note_suiv) == 3 :
        if note_prec[:2] == note_suiv[:2] :
            return False
    else :
        return True

# Diviser et analyser chaque segment
for i in range(len(onset_times) - 1):
    start_time = onset_times[i]
    end_time = onset_times[i + 1]
    
    # Convertir le temps en échantillons
    start_sample = int(start_time * sr)
    end_sample = int(end_time * sr)
    
    duree_time = end_time - start_time

    # Extraire le segment audio
    segment = y[start_sample:end_sample]
    
    # Détection de la fréquence dominante avec librosa.piptrack
    pitches, magnitudes = librosa.piptrack(y=segment, sr=sr)
    notes_in_segment = []
    
    pitches, magnitudes = librosa.piptrack(y=segment, sr=sr, n_fft=nfft, hop_length=hop_length)
    if pitches.any():
        for t in range(pitches.shape[1]):  # Parcourir chaque frame
            index = magnitudes[:, t].argmax()  # Index de la magnitude maximale
            pitch_candidate = pitches[index, t]
            if pitch_candidate > 0:  # Vérifier que la fréquence est valide
                note = librosa.hz_to_note(pitch_candidate)
                notes_in_segment.append(note)

    # Trouver la note la plus fréquente dans ce segment
    if notes_in_segment :
        most_common_note = Counter(notes_in_segment).most_common(1)[0][0]
        if (not detected_notes) or octave(detected_notes[-1][0],most_common_note) :
            midi_note = note_to_midi(most_common_note)
            detected_notes.append((most_common_note, start_time, end_time,pitch_candidate,duree_time,midi_note))

"""
#print(detected_notes)
for note, start, end, freq in detected_notes:
    print(f"Note: {note}, Fréquence : {freq}, Start: {start:.2f}s, End: {end:.2f}s")
"""

# Sauvegarder le fichier MIDI
track = 0
channel = 0
volume = 100  # 0-127, selon la norme MIDI

# Demander à l'utilisateur s'il veut jouer le fichier audio
choix_instru = input("Veuillez choisir l'instrument pour la conversion du son : ").strip().lower()
"""while choix_instru==instrument.lower():
    print("Le morceau est déjà produit par ce fichier\n")
    # Demander à l'utilisateur s'il veut jouer le fichier audio
    choix_instru = input("Veuillez choisir un autre instrument pour la conversion du son : ").strip().lower()"""

program = next((cle for cle, valeur in instruments.items() if valeur.lower() == choix_instru), None)
if program is None:
    print("Instrument non trouvé. Sélection aléatoire...")
    program = random.randint(0, 128)
print(f"La conversion se fera à l'instrument : {instruments.get(program, 'Instrument inconnu')}")
        
# Création du fichier MIDI
midi = MIDIFile(1)

midi.addProgramChange(track, channel, 0, program)

# Ajout des notes au fichier MIDI
for i, (note_name, start,end, freq,duree,midi_note) in enumerate(detected_notes): # frame = duree
    if i < len(detected_notes) - 1 :
        duree = detected_notes[i+1][1] - detected_notes[i][1]
    midi.addNote(track, channel, midi_note, start*2, duree*2, 100)  # Canal 0, vélocité 100

conver_nom=nom_fichier[:-4]+"-"+choix_instru + ".mid"
# Écriture du fichier MIDI
with open(conver_nom, "wb") as output_file:
    midi.writeFile(output_file)

